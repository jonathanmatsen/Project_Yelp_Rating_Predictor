{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Yelp Rating Regression Predictor\n",
    "\n",
    "The restaurant industry is tougher than ever, with restaurant reviews blazing across the Internet from day one of a restaurant's opening. But as a lover of food, you and your friend decide to break into the industry and open up your own restaurant, Danielle's Delicious Delicacies. Since a restaurant's success is highly correlated with its reputation, you want to make sure Danielle's Delicious Delicacies has the best reviews on the most queried restaurant review site: Yelp! While you know your food will be delicious, you think there are other factors that play into a Yelp rating and will ultimately determine your business's success. With a dataset of different restaurant features and their Yelp ratings, you decide to use a Multiple Linear Regression model to investigate what factors most affect a restaurant's Yelp rating and predict the Yelp rating for your restaurant!\n",
    "\n",
    "In this project we'll be working with a real dataset provided by Yelp. We have provided six files, listed below with a brief description:\n",
    "* `yelp_business.json`: establishment data regarding location and attributes for all businesses in the dataset\n",
    "* `yelp_review.json`: Yelp review metadata by business\n",
    "* `yelp_user.json`: user profile metadata by business\n",
    "* `yelp_checkin.json`: online checkin metadata by business\n",
    "* `yelp_tip.json`: tip metadata by business\n",
    "* `yelp_photo.json`: photo metadata by business\n",
    "\n",
    "For a more detailed explanation of the features in each `.json` file, see the accompanying [explanatory feature document](https://docs.google.com/document/d/1V6FjJpKspVBOOBs4E7fBfp_yzHn0--XJkC2uUtWuRgM/edit).\n",
    "\n",
    "Let's get started by exploring the data in each of these files to see what we are working with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d7c40fc11e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load yelp_business.json into dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbusinesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_business.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load yelp_review.json into dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_review.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m             )\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "#load yelp_business.json into dataframe\n",
    "businesses = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_business.json', lines = True)\n",
    "\n",
    "#load yelp_review.json into dataframe\n",
    "reviews = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_review.json', lines=True)\n",
    "\n",
    "#load yelp_user.json into dataframe\n",
    "users = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_user.json', lines=True)\n",
    "\n",
    "#load yelp_checkin.json into dataframe\n",
    "checkins = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_checkin.json', lines=True)\n",
    "\n",
    "#load yelp_tip.json into dataframe\n",
    "tips = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_tip.json', lines=True)\n",
    "\n",
    "#load yelp_photo.json into dataframe\n",
    "photos = pd.read_json('/Users/jonathanmatsen/Documents/3_Projects/yelp_regression_project/yelp_photo.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataframe parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.351977Z",
     "start_time": "2018-09-14T14:51:21.349551Z"
    }
   },
   "outputs": [],
   "source": [
    "# adjust max columns to display as 60 \n",
    "pd.options.display.max_columns = 60\n",
    "\n",
    "# adjust max column width to 500 characters \n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting familiar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.392763Z",
     "start_time": "2018-09-14T14:51:21.354525Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# overview of businesses dataframe \n",
    "businesses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.407101Z",
     "start_time": "2018-09-14T14:51:21.394695Z"
    }
   },
   "outputs": [],
   "source": [
    "# overview of reviews dataframe \n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.419331Z",
     "start_time": "2018-09-14T14:51:21.409377Z"
    }
   },
   "outputs": [],
   "source": [
    "# overview of users dataframe \n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.433534Z",
     "start_time": "2018-09-14T14:51:21.421393Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# overview of checkins dataframe \n",
    "checkins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.445061Z",
     "start_time": "2018-09-14T14:51:21.435743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# overview of tips dataframe \n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.455113Z",
     "start_time": "2018-09-14T14:51:21.446975Z"
    }
   },
   "outputs": [],
   "source": [
    "# overview of photos dataframe \n",
    "photos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many different businesses are in the dataset? What are the different features in the review DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 188,593 businesses. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving Deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.460856Z",
     "start_time": "2018-09-14T14:51:21.456994Z"
    }
   },
   "outputs": [],
   "source": [
    "# dive deeper into structure of data\n",
    "businesses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the range of values for the features in the user DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Number Friends:** _1 - 4219_\n",
    "* **Days on Yelp:** _76 - 4860_\n",
    "* **Number Fans:** _0 - 1174.66_\n",
    "* **Review Count:** _0.66 - 6335_\n",
    "* **Number of Year Elite:** _0 - 10.66_ \n",
    "\n",
    "_All numbers are averages._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics of Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:21.556908Z",
     "start_time": "2018-09-14T14:51:21.462876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# review summary statistics of users  \n",
    "\n",
    "users.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### What feature, or column, do the DataFrames have in common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Business ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge businesses with reviews on business if into new dataframe 'df'\n",
    "df = pd.merge(businesses, reviews, how='left', on='business_id')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge each of the other 4 DataFrames into our new DataFrame `df` to combine all the data together. Make sure that `df` is the left DataFrame in each merge and `how=left` since not every DataFrame includes every business in the dataset (this way we won't lose any data during the merges). Once combined, print out the columns of `df`. What features are in this new DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:24.043166Z",
     "start_time": "2018-09-14T14:51:22.538823Z"
    }
   },
   "outputs": [],
   "source": [
    "# merge users with df and print length of df to ensure accurate number of records during merge\n",
    "df = pd.merge(df, users, how='left', on='business_id')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge checkins with df and print length of df to ensure accurate number of records during merge\n",
    "df = pd.merge(df, checkins, how='left', on='business_id')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tips with df and print length of df to ensure accurate number of records during merge \n",
    "df = pd.merge(df, tips, how='left', on='business_id')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge photos with df and print length of df to ensure accurate number of records during merge\n",
    "df = pd.merge(df, photos, how='left', on='business_id')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify number of columns in df = 40 \n",
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify all expected column names present in final merged df \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview of df \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of non-continuous and non-binary features to remove\n",
    "features_to_remove = ['address','attributes','business_id','categories','city','hours','is_open','latitude','longitude','name','neighborhood','postal_code','state','time'] \n",
    "\n",
    "# remove unwanted attributes \n",
    "df.drop(features_to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:24.649109Z",
     "start_time": "2018-09-14T14:51:24.581948Z"
    }
   },
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:24.661609Z",
     "start_time": "2018-09-14T14:51:24.650866Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace missing values by replacing NaNs w/ 0s \n",
    "df.fillna({'weekday_checkins': 0, \n",
    "           'weekend_checkins': 0, \n",
    "           'average_tip_length': 0, \n",
    "           'number_tips': 0, \n",
    "           'average_caption_length': 0,\n",
    "           'number_pics': 0},\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for any remaining missing values \n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:24.968871Z",
     "start_time": "2018-09-14T14:51:24.725501Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* alcohol: -0.043332\n",
    "* good_for_kids: -0.030382\n",
    "* has_bike_parking: 0.068084\n",
    "* has_wifi: -0.039857\n",
    "* price_range: -0.052565\n",
    "* review_count: 0.032413\n",
    "* **average_review_age: -0.125645**\n",
    "* **average_review_length: -0.277081**\n",
    "* **average_review_sentiment: 0.782187**\n",
    "* average_days_on_yelp: -0.038061\n",
    "* average_number_fans: -0.031141\n",
    "* average_review_count: -0.066572\n",
    "* average_years_elite: -0.064419\n",
    "* average_tip_length: -0.052899\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further visualize these relationships, we can plot certain features against our dependent variable, the Yelp rating. In the cell below we have provided the code to import Matplotlib. We can use Matplotlib's `.scatter()` method with the below syntax to plot what these correlations look like:\n",
    "\n",
    "```python\n",
    "plt.scatter(x_values_to_plot, y_values_to_plot, alpha=blending_val)\n",
    "```\n",
    "\n",
    "* `x_values_to_plot` are the values to be plotted along the x-axis\n",
    "* `y_values_to_plot` are the values to be plotted along the y-axis\n",
    "* `alpha=blending_val` is the blending value, or how transparent (0) or opaque (1) a plotted point is. This will help us distinguish areas of the plot with high point densities and low point densities\n",
    "\n",
    "Plot the three features that correlate most with Yelp rating (`average_review_sentiment`, `average_review_length`, `average_review_age`) against `stars`, our Yelp rating. Then plot a lowly correlating feature, such as `number_funny_votes`, against `stars`.\n",
    "\n",
    ">What is `average_review_sentiment`, you ask? `average_review_sentiment` is the average sentiment score for all reviews on a business' Yelp page. The sentiment score for a review was calculated using the sentiment analysis tool [VADER](https://github.com/cjhutto/vaderSentiment). VADER uses a labeled set of positive and negative words, along with codified rules of grammar, to estimate how positive or negative a statement is. Scores range from `-1`, most negative, to `+1`, most positive, with a score of `0` indicating a neutral statement. While not perfect, VADER does a good job at guessing the sentiment of text data!\n",
    "\n",
    "What kind of relationships do you see from the plots? Do you think these variables are good or bad features for our Yelp rating prediction model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot average_review_sentiment against stars here\n",
    "plt.scatter(df.average_review_sentiment, df.stars, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average_review_length against stars here\n",
    "plt.scatter(df.average_review_length, df.stars, alpha=0.1)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot average_review_age against stars here\n",
    "plt.scatter(df.average_review_age, df.stars, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number_funny_votes against stars here\n",
    "plt.scatter(df.number_funny_votes, df.stars, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Why do you think `average_review_sentiment` correlates so well with Yelp rating?\n",
    "\n",
    "* People are emotional beings and feed off of what other people previously felt. They trust their opinions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection\n",
    "\n",
    "In order to put our data into a Linear Regression model, we need to **separate out our features to model on and the Yelp ratings**. \n",
    "\n",
    "From our correlation analysis we saw that the three features with the strongest correlations to Yelp rating are `average_review_sentiment`, `average_review_length`, and `average_review_age`. \n",
    "\n",
    "Since we want to dig a little deeper than `average_review_sentiment`, which understandably has a very high correlation with Yelp rating, let's choose to create our first model with `average_review_length` and `average_review_age` as features.\n",
    "\n",
    "Pandas lets us select one column of a DataFrame with the following syntax:\n",
    "\n",
    "```python\n",
    "subset_of_data = df['feature_to_select']\n",
    "```\n",
    "Pandas also lets us select multiple columns from a DataFrame with this syntax:\n",
    "\n",
    "```python\n",
    "subset_of_data = df[list_of_features_to_select]\n",
    "```\n",
    "Create a new DataFrame `features` that contains the columns we want to model on: `average_review_length` and `average_review_age`. Then create another DataFrame `ratings` that stores the value we want to predict, Yelp rating, or `stars` in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:57.953014Z",
     "start_time": "2018-09-14T14:51:57.945658Z"
    }
   },
   "outputs": [],
   "source": [
    "features = df[['average_review_length', 'average_review_age']]\n",
    "\n",
    "ratings = df['stars']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets\n",
    "\n",
    "We are just about ready to model! But first, we need to **break our data into a training set and a test set so we can evaluate how well our model performs**. \n",
    "\n",
    "We'll use scikit-learn's `train_test_split` function to do this split, which is provided in the cell below. This function takes **two required parameters: the data, or our features, followed by our dependent variable, in our case the Yelp rating**. \n",
    "\n",
    "Set the optional parameter `test_size` to be `0.2`. Finally, set the optional parameter `random_state` to `1`. This will make it so your data is split in the same way as the data in our solution code. \n",
    "\n",
    "Remember, **this function returns 4 items in this order**:\n",
    "1. The training data (features), which we can assign to `X_train`\n",
    "2. The testing data (features), which we can assign to `X_test`\n",
    "3. The training dependent variable (Yelp rating), which we can assign to `y_train`\n",
    "4. The testing dependent variable (Yelp rating), which we can assign to `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, ratings, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train the Model\n",
    "\n",
    "Now that our data is split into training and testing sets, we can finally model! In the cell below we have provided the code to import `LinearRegression` from scikit-learn's `linear_model` module. \n",
    "\n",
    "**Create a new `LinearRegression` object named model.** \n",
    "\n",
    "_The `.fit()` method will fit our Linear Regression model to our training data and calculate the coefficients for our features._ \n",
    "\n",
    "Call the `.fit()` method on `model` with `X_train` and `y_train` as parameters. Just like that our model has now been trained on our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Understand the Model\n",
    "\n",
    "Now we can evaluate our model in a variety of ways. \n",
    "\n",
    "The first way will be by using the `.score()` method, which provides the R^2 value for our model. \n",
    "* _Remember, R^2 is the coefficient of determination, or a measure of how much of the variance in our dependent variable, the predicted Yelp rating, is explained by our independent variables, our feature data._\n",
    "* R^2 values range from `0` to `1`, with `0` indicating that the created model does not fit our data at all, and with `1` indicating the model perfectly fits our feature data. \n",
    "\n",
    "**Call `.score()` on our model with `X_train` and `y_train` as parameters to calculate our training R^2 score. Then call `.score()` again on model with `X_test` and `y_test` as parameters to calculate R^2 for our testing data**. \n",
    "\n",
    "What do these R^2 values say about our model? Do you think these features alone are able to effectively predict Yelp ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:58.631827Z",
     "start_time": "2018-09-14T14:51:58.619225Z"
    }
   },
   "outputs": [],
   "source": [
    "train_R2 = model.score(x_train, y_train)\n",
    "test_R2 = model.score(x_test, y_test)\n",
    "\n",
    "print(train_R2)\n",
    "print(test_R2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all that hard work, we can finally take a look at the coefficients on our different features! The model has an **attribute `.coef_` which is an array of the feature coefficients determined by fitting our model to the training data**. \n",
    "\n",
    "To make it easier for you to see which feature corresponds to which coefficient, we have provided some code in the cell that `zip`s together a list of our features with the coefficients and sorts them in descending order from most predictive to least predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(['average_review_length','average_review_age'],model.coef_)),key = lambda x: abs(x[1]),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we can **calculate the predicted Yelp ratings for our testing data and compare them to their actual Yelp ratings!** \n",
    "\n",
    "Our model has a `.predict()` method which uses the model's coefficients to calculate the predicted Yelp rating. Call `.predict()` on `X_test` and assign the values to `y_predicted`. Use Matplotlib to plot `y_test` vs `y_predicted`. \n",
    "\n",
    "For a perfect linear regression model we would expect to see the data plotted along the line `y = x`, indicating _homoscedasticity_. Is this the case? If not, why not? Would you call this model _heteroscedastic_ or _homoscedastic_ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:51:58.656842Z",
     "start_time": "2018-09-14T14:51:58.653453Z"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_predicted, y_test, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Different Subsets of Data\n",
    "\n",
    "After evaluating the first model, you can see that `average_review_length` and `average_review_age` alone are not the best predictors for Yelp rating. Let's go do some more modeling with different subsets of features and see if we can achieve a more accurate model! In the cells below we have provided different lists of subsets of features that we will model with and evaluate. What other subsets of features would you want to test? Why do you think those feature sets are more predictive of Yelp rating than others? Create at least one more subset of features that you want to predict Yelp ratings from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of only average review sentiment\n",
    "sentiment = ['average_review_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of all features that have a response range [0,1]\n",
    "binary_features = ['alcohol?','has_bike_parking','takes_credit_cards','good_for_kids','take_reservations','has_wifi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of all features that vary on a greater range than [0,1]\n",
    "numeric_features = ['review_count','price_range','average_caption_length','number_pics','average_review_age','average_review_length','average_review_sentiment','number_funny_votes','number_cool_votes','number_useful_votes','average_tip_length','number_tips','average_number_friends','average_days_on_yelp','average_number_fans','average_review_count','average_number_years_elite','weekday_checkins','weekend_checkins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all features\n",
    "all_features = binary_features + numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own feature subset here\n",
    "feature_subset = ['alcohol?', 'has_bike_parking']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have lists of different feature subsets, we can create new models from them. In order to more easily compare the performance of these new models, we have created a function for you below called `model_these_features()`. This function replicates the model building process you just completed with our first model! Take some time to review how the function works, analyzing it line by line. Fill in the empty comments with an explanation of the task the code beneath it is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# take a list of features to model as a parameter\n",
    "def model_these_features(feature_list):\n",
    "    \n",
    "    # df.loc -- Access a group of rows and columns by label(s) or a boolean array\n",
    "    # gathering ratings=x=dependent variable & features=y=independent variable\n",
    "    ratings = df.loc[:,'stars']\n",
    "    features = df.loc[:,feature_list]\n",
    "    \n",
    "    #splitting variable data into train/test for fitting then testing the model \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, ratings, test_size = 0.2, random_state = 1)\n",
    "    \n",
    "    # don't worry too much about these lines, just know that they allow the model to work when\n",
    "    # we model on just one feature instead of multiple features. Trust us on this one :)\n",
    "    if len(X_train.shape) < 2:\n",
    "        X_train = np.array(X_train).reshape(-1,1)\n",
    "        X_test = np.array(X_test).reshape(-1,1)\n",
    "    \n",
    "    # create model object and fit the model to relevant data \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    # determine R2 values=coefficient of determination. Scale of 0 - 1 and tells us how well independent variables explain the dependent variable\n",
    "    # 0.7 and up is generally considered good \n",
    "    print('Train Score:', model.score(X_train,y_train))\n",
    "    print('Test Score:', model.score(X_test,y_test))\n",
    "    \n",
    "    # print the model features and their corresponding coefficients, from most predictive to least predictive\n",
    "    print(sorted(list(zip(feature_list,model.coef_)),key = lambda x: abs(x[1]),reverse=True))\n",
    "    \n",
    "    # see how well the model predicts the actual y_test variables \n",
    "    y_predicted = model.predict(X_test)\n",
    "    \n",
    "    # visualize the model's accuracy of predicted vs acutal \n",
    "    plt.scatter(y_test,y_predicted)\n",
    "    plt.xlabel('Yelp Rating')\n",
    "    plt.ylabel('Predicted Yelp Rating')\n",
    "    plt.ylim(1,5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you feel comfortable with the steps of the function, run models on the following subsets of data using `model_these_features()`:\n",
    "* `sentiment`: only `average_review_sentiment`\n",
    "* `binary_features`: all features that have a response range [0,1]\n",
    "* `numeric_features`: all features that vary on a greater range than [0,1]\n",
    "* `all_features`: all features\n",
    "* `feature_subset`: your own feature subset\n",
    "\n",
    "How does changing the feature sets affect the model's R^2 value? Which features are most important to predicting Yelp rating in the different models? Which models appear more or less homoscedastic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model on sentiment here\n",
    "sentiment_model = model_these_features(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model on all binary features here\n",
    "binary_model = model_these_features(binary_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model on all numeric features here\n",
    "numeric_model = model_these_features(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model on all features here\n",
    "all_model = model_these_features(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model on your feature subset here\n",
    "subset_model = model_these_features(feature_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Danielle's Delicious Delicacies' Debut\n",
    "\n",
    "You've loaded the data, cleaned it, modeled it, and evaluated it. You're tired, but glowing with pride after all the hard work. You close your eyes and can clearly see opening day of Danielle's Delicious Delicacies with a line out the door. But what will your Yelp rating be? Let's use our model to make a prediction.\n",
    "\n",
    "Our best model was the model using all features, so we'll work with this model again. In the cell below print `all_features` to get a reminder of what features we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-14T14:52:25.658575Z",
     "start_time": "2018-09-14T14:52:25.654756Z"
    }
   },
   "outputs": [],
   "source": [
    "print(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to grab all the features and retrain our model on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:,all_features]\n",
    "ratings = df.loc[:,'stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, ratings, test_size = 0.2, random_state = 1)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give you some perspective on the restaurants already out there, we have provided the mean, minimum, and maximum values for each feature below. Will Danielle's Delicious Delicacies be just another average restaurant, or will it be a 5 star behemoth amongst the masses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(features.columns,features.describe().loc['mean'],features.describe().loc['min'],features.describe().loc['max'])),columns=['Feature','Mean','Min','Max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your plans for the restaurant, how you expect your customers to post on your Yelp page, and the values above, fill in the blanks in the NumPy array below with your desired values. The first blank corresponds with the feature at `index=0` in the DataFrame above, `alcohol?`, and the last blank corresponds to the feature at ``index=24``, `weekend_checkins`. Make sure to enter either `0` or `1` for all binary features, and if you aren't sure of what value to put for a feature, select the mean from the DataFrame above. After you enter the values, run the prediction cell below to receive your Yelp rating! How is Danielle's Delicious Delicacies debut going to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-13T18:35:02.243266Z",
     "start_time": "2018-09-13T18:34:39.238Z"
    }
   },
   "outputs": [],
   "source": [
    "danielles_delicious_delicacies = np.array([1,1,1,0,0,1,2,2,5,10,10,596,0.554935,15.61,18.49,50,45,3,200,2,10,20,0,50,60]).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-13T18:35:02.244175Z",
     "start_time": "2018-09-13T18:34:39.239Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(danielles_delicious_delicacies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You have successfully built a linear regression model that predicts a restaurant's Yelp rating! As you have seen, it can be pretty hard to predict a rating like this even when we have a plethora of data. \n",
    "\n",
    "**What other questions come to your mind when you see the data we have**? \n",
    "\n",
    "**What insights do you think could come from a different kind of analysis? Here are some ideas to ponder**:\n",
    "\n",
    "* Can we predict the cuisine of a restaurant based on the users that review it?\n",
    "* What restaurants are similar to each other in ways besides cuisine?\n",
    "* Are there different restaurant vibes, and what kind of restaurants fit these conceptions?\n",
    "* How does social media status affect a restaurant's credibility and visibility?\n",
    "\n",
    "As you progress further into the field of data science, you will be able to create models that address these questions and many more! But in the meantime, get back to working on that burgeoning restaurant business plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
